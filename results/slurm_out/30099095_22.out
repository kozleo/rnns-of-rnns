Gradient step: 0 	 Performance: 0.05 	 Training loss: 3.82
Gradient step: 24 	 Performance: 0.065 	 Training loss: 30.77
Gradient step: 49 	 Performance: 0.06 	 Training loss: 19.76
Gradient step: 74 	 Performance: 0.075 	 Training loss: 17.39
Gradient step: 99 	 Performance: 0.08 	 Training loss: 16.68
Gradient step: 124 	 Performance: 0.045 	 Training loss: 16.34
Gradient step: 149 	 Performance: 0.065 	 Training loss: 16.19
Gradient step: 174 	 Performance: 0.08 	 Training loss: 16.11
Gradient step: 199 	 Performance: 0.125 	 Training loss: 15.72
Gradient step: 224 	 Performance: 0.16 	 Training loss: 15.02
Gradient step: 249 	 Performance: 0.185 	 Training loss: 13.44
Gradient step: 274 	 Performance: 0.365 	 Training loss: 11.49
Gradient step: 299 	 Performance: 0.255 	 Training loss: 9.71
Gradient step: 324 	 Performance: 0.295 	 Training loss: 8.65
Gradient step: 349 	 Performance: 0.305 	 Training loss: 7.80
Gradient step: 374 	 Performance: 0.54 	 Training loss: 7.25
Gradient step: 399 	 Performance: 0.545 	 Training loss: 6.44
Gradient step: 424 	 Performance: 0.535 	 Training loss: 5.79
Gradient step: 449 	 Performance: 0.565 	 Training loss: 5.31
Gradient step: 474 	 Performance: 0.635 	 Training loss: 5.56
Gradient step: 499 	 Performance: 0.7 	 Training loss: 4.76
Gradient step: 524 	 Performance: 0.84 	 Training loss: 3.97
Gradient step: 549 	 Performance: 0.775 	 Training loss: 3.47
Gradient step: 574 	 Performance: 0.92 	 Training loss: 3.16
Folder '/om2/user/leokoz8/code/rnns-of-rnns/models/None/dlyantiintr/None' already exists!
Gradient step: 0 	 Performance: 0.06 	 Training loss: 2.99
Gradient step: 24 	 Performance: 0.035 	 Training loss: 27.23
Gradient step: 49 	 Performance: 0.055 	 Training loss: 19.57
Gradient step: 74 	 Performance: 0.06 	 Training loss: 17.26
Gradient step: 99 	 Performance: 0.065 	 Training loss: 16.72
Gradient step: 124 	 Performance: 0.115 	 Training loss: 16.42
Gradient step: 149 	 Performance: 0.125 	 Training loss: 16.25
Gradient step: 174 	 Performance: 0.14 	 Training loss: 16.02
Gradient step: 199 	 Performance: 0.105 	 Training loss: 15.72
Gradient step: 224 	 Performance: 0.08 	 Training loss: 15.35
Gradient step: 249 	 Performance: 0.1 	 Training loss: 14.77
Gradient step: 274 	 Performance: 0.145 	 Training loss: 14.21
Gradient step: 299 	 Performance: 0.12 	 Training loss: 13.66
Gradient step: 324 	 Performance: 0.12 	 Training loss: 12.90
Gradient step: 349 	 Performance: 0.22 	 Training loss: 12.03
Gradient step: 374 	 Performance: 0.235 	 Training loss: 11.06
Gradient step: 399 	 Performance: 0.195 	 Training loss: 10.04
Gradient step: 424 	 Performance: 0.255 	 Training loss: 9.21
Gradient step: 449 	 Performance: 0.33 	 Training loss: 8.36
Gradient step: 474 	 Performance: 0.3 	 Training loss: 8.03
Gradient step: 499 	 Performance: 0.33 	 Training loss: 7.35
Gradient step: 524 	 Performance: 0.405 	 Training loss: 6.76
Gradient step: 549 	 Performance: 0.445 	 Training loss: 6.26
Gradient step: 574 	 Performance: 0.415 	 Training loss: 5.73
Gradient step: 599 	 Performance: 0.49 	 Training loss: 5.27
Gradient step: 624 	 Performance: 0.65 	 Training loss: 4.86
Gradient step: 649 	 Performance: 0.73 	 Training loss: 4.33
Gradient step: 674 	 Performance: 0.765 	 Training loss: 3.76
Gradient step: 699 	 Performance: 0.86 	 Training loss: 3.35
Gradient step: 724 	 Performance: 0.795 	 Training loss: 2.93
Gradient step: 749 	 Performance: 0.92 	 Training loss: 2.37
Folder '/om2/user/leokoz8/code/rnns-of-rnns/models/sym/dlyantiintr/conformal' already exists!
Gradient step: 0 	 Performance: 0.04 	 Training loss: 3.82
Gradient step: 24 	 Performance: 0.06 	 Training loss: 33.47
Gradient step: 49 	 Performance: 0.07 	 Training loss: 20.65
Gradient step: 74 	 Performance: 0.055 	 Training loss: 17.77
Gradient step: 99 	 Performance: 0.085 	 Training loss: 16.92
Gradient step: 124 	 Performance: 0.07 	 Training loss: 16.53
Gradient step: 149 	 Performance: 0.09 	 Training loss: 16.41
Gradient step: 174 	 Performance: 0.075 	 Training loss: 16.24
Gradient step: 199 	 Performance: 0.095 	 Training loss: 15.93
Gradient step: 224 	 Performance: 0.11 	 Training loss: 15.60
Gradient step: 249 	 Performance: 0.165 	 Training loss: 14.65
Gradient step: 274 	 Performance: 0.165 	 Training loss: 14.55
Gradient step: 299 	 Performance: 0.21 	 Training loss: 12.29
Gradient step: 324 	 Performance: 0.275 	 Training loss: 9.97
Gradient step: 349 	 Performance: 0.325 	 Training loss: 8.63
Gradient step: 374 	 Performance: 0.335 	 Training loss: 8.03
Gradient step: 399 	 Performance: 0.45 	 Training loss: 7.17
Gradient step: 424 	 Performance: 0.315 	 Training loss: 6.43
Gradient step: 449 	 Performance: 0.555 	 Training loss: 5.83
Gradient step: 474 	 Performance: 0.805 	 Training loss: 5.07
Gradient step: 499 	 Performance: 0.625 	 Training loss: 4.66
Gradient step: 524 	 Performance: 0.73 	 Training loss: 4.60
Gradient step: 549 	 Performance: 0.84 	 Training loss: 3.83
Gradient step: 574 	 Performance: 0.7 	 Training loss: 3.12
Gradient step: 599 	 Performance: 0.78 	 Training loss: 4.37
Gradient step: 624 	 Performance: 0.875 	 Training loss: 3.06
Gradient step: 649 	 Performance: 0.96 	 Training loss: 2.19
Folder '/om2/user/leokoz8/code/rnns-of-rnns/models/sym/dlyantiintr/None' already exists!
Gradient step: 0 	 Performance: 0.075 	 Training loss: 2.99
Gradient step: 24 	 Performance: 0.035 	 Training loss: 28.20
Gradient step: 49 	 Performance: 0.025 	 Training loss: 19.81
Gradient step: 74 	 Performance: 0.105 	 Training loss: 17.45
Gradient step: 99 	 Performance: 0.075 	 Training loss: 16.82
Gradient step: 124 	 Performance: 0.065 	 Training loss: 16.44
Gradient step: 149 	 Performance: 0.075 	 Training loss: 16.34
Gradient step: 174 	 Performance: 0.075 	 Training loss: 16.14
Gradient step: 199 	 Performance: 0.1 	 Training loss: 15.75
Gradient step: 224 	 Performance: 0.08 	 Training loss: 15.50
Gradient step: 249 	 Performance: 0.06 	 Training loss: 15.06
Gradient step: 274 	 Performance: 0.15 	 Training loss: 14.54
Gradient step: 299 	 Performance: 0.085 	 Training loss: 14.17
Gradient step: 324 	 Performance: 0.135 	 Training loss: 13.54
Gradient step: 349 	 Performance: 0.165 	 Training loss: 12.78
Gradient step: 374 	 Performance: 0.145 	 Training loss: 11.67
Gradient step: 399 	 Performance: 0.145 	 Training loss: 10.86
Gradient step: 424 	 Performance: 0.2 	 Training loss: 9.86
Gradient step: 449 	 Performance: 0.205 	 Training loss: 8.93
Gradient step: 474 	 Performance: 0.245 	 Training loss: 8.25
Gradient step: 499 	 Performance: 0.25 	 Training loss: 7.98
Gradient step: 524 	 Performance: 0.315 	 Training loss: 7.45
Gradient step: 549 	 Performance: 0.37 	 Training loss: 6.92
Gradient step: 574 	 Performance: 0.305 	 Training loss: 6.58
Gradient step: 599 	 Performance: 0.425 	 Training loss: 6.20
Gradient step: 624 	 Performance: 0.555 	 Training loss: 5.64
Gradient step: 649 	 Performance: 0.6 	 Training loss: 5.03
Gradient step: 674 	 Performance: 0.53 	 Training loss: 4.57
Gradient step: 699 	 Performance: 0.755 	 Training loss: 4.03
Gradient step: 724 	 Performance: 0.735 	 Training loss: 3.50
Gradient step: 749 	 Performance: 0.85 	 Training loss: 3.20
Gradient step: 774 	 Performance: 0.775 	 Training loss: 2.90
Gradient step: 799 	 Performance: 0.88 	 Training loss: 2.49
Gradient step: 824 	 Performance: 0.875 	 Training loss: 2.14
Gradient step: 849 	 Performance: 0.965 	 Training loss: 1.88
Folder '/om2/user/leokoz8/code/rnns-of-rnns/models/spectral/dlyantiintr/conformal' created successfully!
Gradient step: 0 	 Performance: 0.04 	 Training loss: 3.82
Gradient step: 24 	 Performance: 0.075 	 Training loss: 31.95
Gradient step: 49 	 Performance: 0.07 	 Training loss: 19.87
Gradient step: 74 	 Performance: 0.025 	 Training loss: 17.39
Gradient step: 99 	 Performance: 0.04 	 Training loss: 16.84
Gradient step: 124 	 Performance: 0.05 	 Training loss: 16.42
Gradient step: 149 	 Performance: 0.08 	 Training loss: 16.25
Gradient step: 174 	 Performance: 0.04 	 Training loss: 16.04
Gradient step: 199 	 Performance: 0.065 	 Training loss: 15.52
Gradient step: 224 	 Performance: 0.205 	 Training loss: 14.05
Gradient step: 249 	 Performance: 0.265 	 Training loss: 11.95
Gradient step: 274 	 Performance: 0.4 	 Training loss: 10.01
Gradient step: 299 	 Performance: 0.2 	 Training loss: 8.99
Gradient step: 324 	 Performance: 0.32 	 Training loss: 8.03
Gradient step: 349 	 Performance: 0.43 	 Training loss: 7.25
Gradient step: 374 	 Performance: 0.55 	 Training loss: 6.50
Gradient step: 399 	 Performance: 0.59 	 Training loss: 6.06
Gradient step: 424 	 Performance: 0.72 	 Training loss: 5.35
Gradient step: 449 	 Performance: 0.59 	 Training loss: 4.96
Gradient step: 474 	 Performance: 0.67 	 Training loss: 4.49
Gradient step: 499 	 Performance: 0.715 	 Training loss: 3.89
Gradient step: 524 	 Performance: 0.795 	 Training loss: 3.56
Gradient step: 549 	 Performance: 0.635 	 Training loss: 3.19
Gradient step: 574 	 Performance: 0.905 	 Training loss: 3.19
Folder '/om2/user/leokoz8/code/rnns-of-rnns/models/spectral/dlyantiintr/None' already exists!
