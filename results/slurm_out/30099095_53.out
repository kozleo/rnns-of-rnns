Gradient step: 0 	 Performance: 0.075 	 Training loss: 2.99
Gradient step: 24 	 Performance: 0.06 	 Training loss: 46.06
Gradient step: 49 	 Performance: 0.06 	 Training loss: 24.10
Gradient step: 74 	 Performance: 0.08 	 Training loss: 20.89
Gradient step: 99 	 Performance: 0.08 	 Training loss: 19.59
Gradient step: 124 	 Performance: 0.075 	 Training loss: 18.28
Gradient step: 149 	 Performance: 0.12 	 Training loss: 17.08
Gradient step: 174 	 Performance: 0.175 	 Training loss: 16.00
Gradient step: 199 	 Performance: 0.135 	 Training loss: 14.90
Gradient step: 224 	 Performance: 0.19 	 Training loss: 13.93
Gradient step: 249 	 Performance: 0.3 	 Training loss: 13.03
Gradient step: 274 	 Performance: 0.265 	 Training loss: 12.48
Gradient step: 299 	 Performance: 0.315 	 Training loss: 11.72
Gradient step: 324 	 Performance: 0.35 	 Training loss: 11.34
Gradient step: 349 	 Performance: 0.4 	 Training loss: 10.59
Gradient step: 374 	 Performance: 0.38 	 Training loss: 9.98
Gradient step: 399 	 Performance: 0.48 	 Training loss: 9.25
Gradient step: 424 	 Performance: 0.47 	 Training loss: 8.67
Gradient step: 449 	 Performance: 0.68 	 Training loss: 8.31
Gradient step: 474 	 Performance: 0.68 	 Training loss: 7.89
Gradient step: 499 	 Performance: 0.7 	 Training loss: 7.30
Gradient step: 524 	 Performance: 0.645 	 Training loss: 6.83
Gradient step: 549 	 Performance: 0.77 	 Training loss: 6.45
Gradient step: 574 	 Performance: 0.735 	 Training loss: 5.89
Gradient step: 599 	 Performance: 0.83 	 Training loss: 5.59
Gradient step: 624 	 Performance: 0.795 	 Training loss: 4.95
Gradient step: 649 	 Performance: 0.825 	 Training loss: 5.30
Gradient step: 674 	 Performance: 0.675 	 Training loss: 4.42
Gradient step: 699 	 Performance: 0.885 	 Training loss: 4.20
Gradient step: 724 	 Performance: 0.895 	 Training loss: 4.10
Gradient step: 749 	 Performance: 0.84 	 Training loss: 3.74
Gradient step: 774 	 Performance: 0.81 	 Training loss: 3.72
Gradient step: 799 	 Performance: 0.905 	 Training loss: 3.23
Folder '/om2/user/leokoz8/code/rnns-of-rnns/models/None/dlydm1seqr/None' already exists!
Gradient step: 0 	 Performance: 0.055 	 Training loss: 3.06
Gradient step: 24 	 Performance: 0.06 	 Training loss: 32.86
Gradient step: 49 	 Performance: 0.06 	 Training loss: 22.09
Gradient step: 74 	 Performance: 0.09 	 Training loss: 19.56
Gradient step: 99 	 Performance: 0.145 	 Training loss: 17.43
Gradient step: 124 	 Performance: 0.28 	 Training loss: 14.12
Gradient step: 149 	 Performance: 0.42 	 Training loss: 11.16
Gradient step: 174 	 Performance: 0.47 	 Training loss: 8.85
Gradient step: 199 	 Performance: 0.51 	 Training loss: 7.95
Gradient step: 224 	 Performance: 0.555 	 Training loss: 7.07
Gradient step: 249 	 Performance: 0.685 	 Training loss: 6.74
Gradient step: 274 	 Performance: 0.6 	 Training loss: 6.26
Gradient step: 299 	 Performance: 0.725 	 Training loss: 5.66
Gradient step: 324 	 Performance: 0.72 	 Training loss: 5.44
Gradient step: 349 	 Performance: 0.72 	 Training loss: 5.04
Gradient step: 374 	 Performance: 0.76 	 Training loss: 4.82
Gradient step: 399 	 Performance: 0.775 	 Training loss: 4.82
Gradient step: 424 	 Performance: 0.83 	 Training loss: 4.36
Gradient step: 449 	 Performance: 0.785 	 Training loss: 4.06
Gradient step: 474 	 Performance: 0.85 	 Training loss: 3.93
Gradient step: 499 	 Performance: 0.845 	 Training loss: 3.69
Gradient step: 524 	 Performance: 0.82 	 Training loss: 3.75
Gradient step: 549 	 Performance: 0.835 	 Training loss: 3.72
Gradient step: 574 	 Performance: 0.85 	 Training loss: 3.28
Gradient step: 599 	 Performance: 0.89 	 Training loss: 3.08
Gradient step: 624 	 Performance: 0.925 	 Training loss: 2.98
Folder '/om2/user/leokoz8/code/rnns-of-rnns/models/sym/dlydm1seqr/conformal' already exists!
Gradient step: 0 	 Performance: 0.06 	 Training loss: 2.99
Gradient step: 24 	 Performance: 0.055 	 Training loss: 51.37
Gradient step: 49 	 Performance: 0.07 	 Training loss: 24.62
Gradient step: 74 	 Performance: 0.055 	 Training loss: 21.12
Gradient step: 99 	 Performance: 0.05 	 Training loss: 19.70
Gradient step: 124 	 Performance: 0.05 	 Training loss: 18.33
Gradient step: 149 	 Performance: 0.225 	 Training loss: 16.85
Gradient step: 174 	 Performance: 0.2 	 Training loss: 15.97
Gradient step: 199 	 Performance: 0.16 	 Training loss: 15.15
Gradient step: 224 	 Performance: 0.22 	 Training loss: 14.24
Gradient step: 249 	 Performance: 0.16 	 Training loss: 13.33
Gradient step: 274 	 Performance: 0.405 	 Training loss: 12.37
Gradient step: 299 	 Performance: 0.435 	 Training loss: 11.89
Gradient step: 324 	 Performance: 0.415 	 Training loss: 11.41
Gradient step: 349 	 Performance: 0.315 	 Training loss: 11.15
Gradient step: 374 	 Performance: 0.585 	 Training loss: 10.22
Gradient step: 399 	 Performance: 0.495 	 Training loss: 9.65
Gradient step: 424 	 Performance: 0.48 	 Training loss: 8.99
Gradient step: 449 	 Performance: 0.6 	 Training loss: 8.35
Gradient step: 474 	 Performance: 0.52 	 Training loss: 7.69
Gradient step: 499 	 Performance: 0.68 	 Training loss: 7.41
Gradient step: 524 	 Performance: 0.76 	 Training loss: 6.69
Gradient step: 549 	 Performance: 0.755 	 Training loss: 6.17
Gradient step: 574 	 Performance: 0.83 	 Training loss: 5.64
Gradient step: 599 	 Performance: 0.855 	 Training loss: 5.06
Gradient step: 624 	 Performance: 0.83 	 Training loss: 4.65
Gradient step: 649 	 Performance: 0.775 	 Training loss: 4.74
Gradient step: 674 	 Performance: 0.73 	 Training loss: 4.32
Gradient step: 699 	 Performance: 0.83 	 Training loss: 3.87
Gradient step: 724 	 Performance: 0.895 	 Training loss: 3.89
Gradient step: 749 	 Performance: 0.9 	 Training loss: 3.54
Folder '/om2/user/leokoz8/code/rnns-of-rnns/models/sym/dlydm1seqr/None' created successfully!
Gradient step: 0 	 Performance: 0.04 	 Training loss: 3.05
Gradient step: 24 	 Performance: 0.085 	 Training loss: 32.51
Gradient step: 49 	 Performance: 0.075 	 Training loss: 21.83
Gradient step: 74 	 Performance: 0.09 	 Training loss: 19.44
Gradient step: 99 	 Performance: 0.21 	 Training loss: 16.54
Gradient step: 124 	 Performance: 0.325 	 Training loss: 13.30
Gradient step: 149 	 Performance: 0.32 	 Training loss: 10.78
Gradient step: 174 	 Performance: 0.38 	 Training loss: 9.00
Gradient step: 199 	 Performance: 0.535 	 Training loss: 7.90
Gradient step: 224 	 Performance: 0.68 	 Training loss: 7.39
Gradient step: 249 	 Performance: 0.625 	 Training loss: 6.69
Gradient step: 274 	 Performance: 0.67 	 Training loss: 6.64
Gradient step: 299 	 Performance: 0.675 	 Training loss: 6.13
Gradient step: 324 	 Performance: 0.69 	 Training loss: 5.49
Gradient step: 349 	 Performance: 0.745 	 Training loss: 5.48
Gradient step: 374 	 Performance: 0.725 	 Training loss: 4.91
Gradient step: 399 	 Performance: 0.69 	 Training loss: 4.65
Gradient step: 424 	 Performance: 0.8 	 Training loss: 4.39
Gradient step: 449 	 Performance: 0.83 	 Training loss: 4.13
Gradient step: 474 	 Performance: 0.815 	 Training loss: 3.81
Gradient step: 499 	 Performance: 0.87 	 Training loss: 3.67
Gradient step: 524 	 Performance: 0.865 	 Training loss: 3.56
Gradient step: 549 	 Performance: 0.885 	 Training loss: 3.56
Gradient step: 574 	 Performance: 0.82 	 Training loss: 3.33
Gradient step: 599 	 Performance: 0.885 	 Training loss: 2.99
Gradient step: 624 	 Performance: 0.875 	 Training loss: 2.97
Gradient step: 649 	 Performance: 0.865 	 Training loss: 2.67
Gradient step: 674 	 Performance: 0.89 	 Training loss: 2.58
Gradient step: 699 	 Performance: 0.9 	 Training loss: 2.79
Folder '/om2/user/leokoz8/code/rnns-of-rnns/models/spectral/dlydm1seqr/conformal' created successfully!
Gradient step: 0 	 Performance: 0.055 	 Training loss: 2.98
Gradient step: 24 	 Performance: 0.065 	 Training loss: 49.19
Gradient step: 49 	 Performance: 0.08 	 Training loss: 24.53
Gradient step: 74 	 Performance: 0.06 	 Training loss: 21.11
Gradient step: 99 	 Performance: 0.055 	 Training loss: 19.96
Gradient step: 124 	 Performance: 0.075 	 Training loss: 18.75
Gradient step: 149 	 Performance: 0.115 	 Training loss: 17.39
Gradient step: 174 	 Performance: 0.175 	 Training loss: 16.14
Gradient step: 199 	 Performance: 0.195 	 Training loss: 15.15
Gradient step: 224 	 Performance: 0.225 	 Training loss: 13.88
Gradient step: 249 	 Performance: 0.28 	 Training loss: 12.92
Gradient step: 274 	 Performance: 0.385 	 Training loss: 12.12
Gradient step: 299 	 Performance: 0.48 	 Training loss: 11.32
Gradient step: 324 	 Performance: 0.45 	 Training loss: 10.70
Gradient step: 349 	 Performance: 0.505 	 Training loss: 10.21
Gradient step: 374 	 Performance: 0.455 	 Training loss: 9.55
Gradient step: 399 	 Performance: 0.62 	 Training loss: 8.84
Gradient step: 424 	 Performance: 0.655 	 Training loss: 7.89
Gradient step: 449 	 Performance: 0.71 	 Training loss: 7.28
Gradient step: 474 	 Performance: 0.705 	 Training loss: 7.06
Gradient step: 499 	 Performance: 0.7 	 Training loss: 6.44
Gradient step: 524 	 Performance: 0.635 	 Training loss: 5.99
Gradient step: 549 	 Performance: 0.715 	 Training loss: 6.12
Gradient step: 574 	 Performance: 0.715 	 Training loss: 5.10
Gradient step: 599 	 Performance: 0.795 	 Training loss: 5.38
Gradient step: 624 	 Performance: 0.87 	 Training loss: 4.34
Gradient step: 649 	 Performance: 0.755 	 Training loss: 4.32
Gradient step: 674 	 Performance: 0.87 	 Training loss: 3.65
Gradient step: 699 	 Performance: 0.86 	 Training loss: 5.76
Gradient step: 724 	 Performance: 0.885 	 Training loss: 4.29
Gradient step: 749 	 Performance: 0.94 	 Training loss: 3.39
Folder '/om2/user/leokoz8/code/rnns-of-rnns/models/spectral/dlydm1seqr/None' created successfully!
